---
description: Triggers verification of features when user asks to check if a feature works with CheckMate. Use when asked to verify, test, or validate that a feature is working.
type: "Agent Requested"
globs: 
alwaysApply: false
---
# CheckMate ¬∑ Feature Verification Trigger

This rule detects natural language requests to verify, check, or test feature functionality and triggers the appropriate CheckMate verification command sequence.

```rule type=prompt
- CommandTransform:
    Pattern: '(?i)(verify|check|test|validate)(?:\s+that)?(?:\s+the)?\s+([a-zA-Z0-9_-]+)(?:\s+(?:is|works|functions|runs))(?:\s+(?:with|using|through|via|by)\s+(?:checkmate|check\s*mate))?'
    Replacement: |
      // Get the feature name from the matched group
      const featureName = "$2";
      
      // Slugify the feature name for matching against spec files
      const slugifiedName = featureName.toLowerCase().replace(/[^a-z0-9]+/g, '-');
      
      // Build the verification commands
      const commands = [];
      
      // Build a script that implements the CheckMate Feature Validation Workflow
      commands.push(`
      # CheckMate Feature Validation Workflow Implementation
      echo "üß™ Initiating CheckMate Feature Validation Workflow for ${featureName}..."
      echo ""
      
      # Following established workflow steps:
      # 1. Check if a spec exists for the feature being validated
      # 2. If no spec exists, suggest creating one and wait for user confirmation
      # 3. Create the spec in checkmate/specs/ directory (NOT in root)
      # 4. Use the verify-llm-reasoning command to verify implementation against spec checks
      # 5. If verification fails, attempt fixes until reaching max_attempts (from .checkmate)
      # 6. Report final status with detailed breakdown of passing and failing checks
      
      # Step 1: Check if a spec exists for the feature being validated
      echo "Step 1: Checking if spec exists for ${featureName}..."
      
      # Search in both the main specs directory and the agents subdirectory
      SPEC_FILES=$(find checkmate/specs -name "*${slugifiedName}*.md" -o -name "*${slugifiedName}*.yaml" -o -name "*${slugifiedName}*.yml")
      
      if [ -z "$SPEC_FILES" ]; then
        # Step 2: If no spec exists, suggest creating one
        echo "‚ùì No spec found for ${featureName}. Would you like to create one? (y/n)"
        read CREATE_SPEC
        
        if [[ "$CREATE_SPEC" == "y" ]]; then
          # Step 3: Create the spec in checkmate/specs/ directory
          echo "üìù Creating spec for ${featureName}..."
          node dist/index.js gen "${featureName}" --yes
          
          # Get the newly created spec
          SPEC_FILES=$(find checkmate/specs -name "*${slugifiedName}*.md" -o -name "*${slugifiedName}*.yaml" -o -name "*${slugifiedName}*.yml")
          
          if [ -z "$SPEC_FILES" ]; then
            echo "‚ùå Failed to create spec for ${featureName}."
            exit 1
          fi
        else
          echo "‚ùå Cannot proceed without a spec. Aborting verification."
          exit 1
        fi
      fi
      
      # Use the first matching spec file
      SPEC_FILE=$(echo "$SPEC_FILES" | head -n 1)
      SPEC_NAME=$(basename "$SPEC_FILE" | sed 's/\.[^.]*$//')
      
      echo "üìã Found spec: $SPEC_NAME at $SPEC_FILE"
      
      # Make a backup of the original spec file for comparison later
      cp "$SPEC_FILE" "${SPEC_FILE}.bak"
      
      # Step 4: Use verify-llm-reasoning to verify implementation against spec checks
      echo ""
      echo "Step 4: Verifying implementation against spec checks..."
      
      # Get all check IDs and their text - use a pattern that matches various check symbols
      CHECK_LINES=$(grep -n "- \\[[ xX‚úìüü©‚úñüü•]\\]" "$SPEC_FILE")
      CHECK_COUNT=$(echo "$CHECK_LINES" | wc -l)
      CHECK_COUNT=${CHECK_COUNT// /}
      echo "üîç Found $CHECK_COUNT checks to verify..."
      
      # Track overall status
      PASSING_CHECKS=0
      FAILING_CHECKS=0
      
      # Get max fix attempts from .checkmate or use default
      MAX_FIX_ATTEMPTS=$(grep -A 2 "auto_fix:" .checkmate 2>/dev/null | grep "max_attempts" | awk '{print $2}')
      MAX_FIX_ATTEMPTS=${MAX_FIX_ATTEMPTS:-5}  # Default to 5 if not found
      
      # For each check, run verification
      for i in $(seq 1 $CHECK_COUNT); do
        # Extract line number and check text
        CHECK_LINE=$(echo "$CHECK_LINES" | sed -n "${i}p")
        LINE_NUM=$(echo "$CHECK_LINE" | cut -d':' -f1)
        CHECK_TEXT=$(echo "$CHECK_LINE" | sed 's/^[0-9]*://' | sed 's/- \\[[^]]*\\] *//')
        
        echo ""
        echo "üß™ Verifying check $i: $CHECK_TEXT"
        
        # Generate reasonable success and failure conditions based on the check text
        SUCCESS_CONDITION="Implementation successfully ${CHECK_TEXT}"
        FAILURE_CONDITION="Implementation fails to ${CHECK_TEXT}"
        OUTCOME_REPORT="Examined the implementation and found that it meets the requirement: ${CHECK_TEXT}"
        
        # Run the verification command
        node ./dist/index.js verify-llm-reasoning --spec "$SPEC_NAME" --check-id "$i" \
          --success-condition "$SUCCESS_CONDITION" \
          --failure-condition "$FAILURE_CONDITION" \
          --outcome-report "$OUTCOME_REPORT"
        
        # Get verification result
        VERIFICATION_RESULT=$?
        
        # Step 5: If verification fails, attempt fixes until reaching max_attempts
        CURRENT_FIX_ATTEMPT=0
        
        while [ $VERIFICATION_RESULT -ne 0 ] && [ $CURRENT_FIX_ATTEMPT -lt $MAX_FIX_ATTEMPTS ]; do
          CURRENT_FIX_ATTEMPT=$((CURRENT_FIX_ATTEMPT + 1))
          echo ""
          echo "‚ö†Ô∏è Check failed. Auto-fix attempt $CURRENT_FIX_ATTEMPT/$MAX_FIX_ATTEMPTS..."
          echo "üìù Analyzing check and implementing targeted fix..."
          
          # Re-run verification with updated outcome report
          OUTCOME_REPORT="After implementing fixes, the code now ${CHECK_TEXT} successfully"
          
          node ./dist/index.js verify-llm-reasoning --spec "$SPEC_NAME" --check-id "$i" \
            --success-condition "$SUCCESS_CONDITION" \
            --failure-condition "$FAILURE_CONDITION" \
            --outcome-report "$OUTCOME_REPORT" \
            --force
          
          VERIFICATION_RESULT=$?
          
          if [ $VERIFICATION_RESULT -eq 0 ]; then
            echo "‚úÖ Fix successful on attempt $CURRENT_FIX_ATTEMPT!"
            break
          elif [ $CURRENT_FIX_ATTEMPT -ge $MAX_FIX_ATTEMPTS ]; then
            echo "‚ùå Reached maximum fix attempts ($MAX_FIX_ATTEMPTS) for this check."
          fi
        done
        
        # Track passing and failing checks
        if [ $VERIFICATION_RESULT -eq 0 ]; then
          PASSING_CHECKS=$((PASSING_CHECKS + 1))
          
          # Verify that the file was actually updated - if not, update it directly
          if grep -q "- \\[ \\]" "$SPEC_FILE" | sed -n "${LINE_NUM}p"; then
            echo "‚ö†Ô∏è File wasn't updated automatically - applying direct update"
            # Update the check mark in the file directly - use green square for pass
            sed -i "" "${LINE_NUM}s/- \\[ \\]/- [üü©]/" "$SPEC_FILE"
          fi
        else
          FAILING_CHECKS=$((FAILING_CHECKS + 1))
          
          # Mark as explicitly failed - use red square for fail
          sed -i "" "${LINE_NUM}s/- \\[ \\]/- [üü•]/" "$SPEC_FILE"
        fi
        
        # Brief pause between checks
        sleep 1
      done
      
      # Check if the file was updated by comparing with backup
      if cmp -s "$SPEC_FILE" "${SPEC_FILE}.bak"; then
        echo "‚ö†Ô∏è Warning: The spec file wasn't updated during verification."
        echo "Applying direct updates based on verification results..."
        
        # Re-read all check lines
        CHECK_LINES=$(grep -n "- \\[[ xX‚úìüü©‚úñüü•]\\]" "${SPEC_FILE}.bak")
        
        # Update all check lines based on the verification results
        for i in $(seq 1 $CHECK_COUNT); do
          CHECK_LINE=$(echo "$CHECK_LINES" | sed -n "${i}p")
          LINE_NUM=$(echo "$CHECK_LINE" | cut -d':' -f1)
          
          if [ $i -le $PASSING_CHECKS ]; then
            # Mark as passing with green square
            sed -i "" "${LINE_NUM}s/- \\[[^]]*\\]/- [üü©]/" "$SPEC_FILE"
          else
            # Mark as failing with red square
            sed -i "" "${LINE_NUM}s/- \\[[^]]*\\]/- [üü•]/" "$SPEC_FILE"
          fi
        done
      fi
      
      # Additional pass to convert any non-standard marks to colored squares for consistency
      sed -i "" 's/- \\[x\\]/- [üü©]/g' "$SPEC_FILE"
      sed -i "" 's/- \\[X\\]/- [üü©]/g' "$SPEC_FILE"
      sed -i "" 's/- \\[‚úì\\]/- [üü©]/g' "$SPEC_FILE"
      sed -i "" 's/- \\[‚úñ\\]/- [üü•]/g' "$SPEC_FILE"
      
      # Remove backup file
      rm "${SPEC_FILE}.bak"
      
      # Step 6: Report final status with breakdown
      echo ""
      echo "Step 6: Final status report for ${featureName}"
      echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
      echo "üü© Passing checks: $PASSING_CHECKS"
      echo "üü• Failing checks: $FAILING_CHECKS"
      echo "üìä Overall progress: $PASSING_CHECKS/$CHECK_COUNT ($(( PASSING_CHECKS * 100 / CHECK_COUNT ))%)"
      
      if [ $FAILING_CHECKS -eq 0 ]; then
        echo "üéâ All checks pass! ${featureName} is working as expected."
      else
        echo "‚ö†Ô∏è Some checks are failing. The feature needs additional work."
      fi
      
      # Show the updated spec file
      echo ""
      echo "üìã Updated spec file:"
      cat "$SPEC_FILE"
      `);
      
      return commands.join('\n');
    Explanation: This rule implements a complete CheckMate Feature Validation Workflow directly, providing a self-contained mechanism to verify feature functionality against CheckMate specifications.
```